# Project Baarat: Empowering Regional Languages in India ğŸ‡®ğŸ‡³ with AI


<div align="center">
   
   # Project Baarat ğŸš€
   
   ![Project Baarat](https://github.com/asphytheghoul/Baarat/assets/52605103/8c1ba4c4-03e6-4067-9a8e-fb65b7d8a2e0)
</div>

Project Baarat is an open-source initiative to leverage the power of
LLMs on Indic-NLP tasks. We aim to build Continually pre-trained, Task
Specific Language Models in a Mixture of Experts (MoE) setup through
domain adaptive pre-training. We plan on making a **multilingual**
**and**  **cross-lingual** LLM that is :

  

> 1\) Pre-trained on a large text corpus containing various sources of
> knowledge including crawled wikipedia articles, textbooks, news,
> social media sites, magazines etc.

>

> 2\) Is continually pre-trained on different downstream tasks. We first
> train a 7B LLaMa-2 model on an unsupervised text corpus in the target
> language and save it as a base model. We have considered the following
> tasks as downstream tasks that will be incorporated in the fine-tuning
> process:

>

> â— Machine Translation 
> â— Text Summarization 
> â— Question Answering 
> â— Instruct Fine-Tuning

>

> (this list is subject to change and a few tasks may be added over time).
  
## About Project Baarat ğŸ“–

Project Baarat is dedicated to making indigenous (regional) languages more accessible. With a focus on the rich linguistic diversity of India. This project aims to break language barriers and promote inclusivity through technology.
<br/>
<br/>

### Key Features âœ¨

- **Tokenizers for Indian Languages**: Robust tokenization tools tailored for the unique structures of regional Indian languages.
- **Fine-tuned Language Models**: Leveraging the power of Large Language Models (LLMs) fine-tuned for Indian languages to understand and generate text with high accuracy.
- **Open Source Collaboration**: We believe in the collective power of the community to drive innovation and inclusivity. ğŸ¤
<br/>
<br/>

## Our Vision ğŸŒŸ

To promote the spirit of building accessible models in native languages, fostering a world where technology speaks everyone's language. ğŸ—£ï¸
<br/>
<br/>

## Roadmap ğŸ›£ï¸

- âœ… ~~Prepare and setup dataset~~
- âœ… ~~Prepare and setup tokenizers~~
- âœ… ~~Start pre-training~~
- âœ… ~~Fine-tune models~~
- â¬œ Implement gating mechanism


Foundational model: LLaMa-2 7B
<br/>



## Contribute to Project Baarat ğŸ› ï¸

We welcome open-source contributions! Whether you're a coder, a linguist, or just someone passionate about language accessibility, there's a place for you in Project Baarat. Here's how you can get involved:

1. **Star and Fork**: Give us a star â­ on GitHub and fork the repository to start contributing.
2. **Issue Tracker**: Report bugs or suggest new features by creating an issue.
3. **Pull Requests**: Submit your pull requests with new features, bug fixes, or documentation enhancements.

Check out our [CONTRIBUTING.md](./CONTRIBUTING.md) for more detailed guidelines.
<br/>
<br/>

## License ğŸ“„

Project Baarat is released under the [MIT License](./LICENSE).
<br/>
<br/>

## Show Your Support ğŸŒˆ

If you like Project Baarat, please consider starring the repository and sharing it with your network!
<br/>
<br/>

---

Made with â¤ï¸ by Team Baarat,\
  [Akash Kamalesh](https://github.com/asphytheghoul) , [Anirudh Lakhotia](https://github.com/anirudhlakhotia/) and [Tanistha Hota](https://github.com/hota15), PES University, Bengaluru.



